# LexVeritas：基于区块链可信存证与检索增强生成（vRAG）的法律智能问答系统深度设计报告

## 1. 项目概述与背景 (Introduction & Background)

### 1.1 引言：从“甚至无法信任律师”到“重建法律 AI 的信任”

随着大语言模型（LLM）技术的爆发，法律行业面临着双重挑战。一方面，通用模型（如 ChatGPT）在回答法律问题时常产生“幻觉”（Hallucination），捏造不存在的法条或判例（如著名的 Mata v. Avianca 案）；另一方面，即便使用 RAG（检索增强生成）技术，如果底层的知识库数据被恶意篡改、过时或污染，AI 输出的答案依然是错误的。

在法律咨询场景中，​ **“真实性”高于“创造性”** ​。用户不再需要一个仅仅能“起草文本”的助手，而是迫切需要一个能\*\*“基于绝对真实依据回答问题”\*\*的智能顾问。

### 1.2 项目愿景：LexVeritas

LexVeritas 是一个 ​**基于区块链可信存证的法律智能问答系统**​。与传统的法律 AI 不同，本项目不追求模型的自由发挥，而是追求\*\*“无依据，不回答”\*\*（No Citation, No Answer）的严谨性。

系统的核心逻辑发生了根本性转变：我们不再去验证用户写的文档，而是 ​**构建一个不可篡改的法律知识库**​。当用户提问时，系统从该知识库中检索相关段落，并在回答的同时，提供该段落的 ​**链上完整性证明（Proof of Data Integrity）** 。这确保了 AI 给出的每一个建议、引用的每一条法律，都源自经过确权的权威数据，彻底消除了数据源被篡改或 AI 胡编乱造的风险。

### 1.3 核心解决的问题

1. ​**绝对真实的数据源（Immutable Truth）** ： 防止“数据投毒”或数据库被黑客篡改。通过将法律文档的哈希指纹上链，确保 AI 检索到的每一条法律依据都与原始权威版本完全一致。
2. ​**消除问答幻觉（Hallucination Elimination）** ： 强制 LLM 仅基于检索到的、经验证的上下文（Context）生成答案，杜绝捏造案例。
3. ​**可追溯的法律建议（Traceable Advice）** ： 每一句生成的回答都会自动标注来源（Citation），并附带该来源的链上哈希证明，让用户可以像查阅原件一样信任 AI 的回答。

---

## 2. 前端设计与用户体验 (UI/UX Design)

### 2.1 “有据可依”的交互界面

界面设计类似于 Perplexity AI 或 Bing Chat，但更加强调 ​**法律依据的不可篡改性**。

- ​**主问答区**：流畅的对话体验。
- ​**证据面板 (Evidence Panel)** ：

  - 当 AI 提到“根据《刑法》第 20 条”时，用户悬停鼠标。
  - 系统弹出一个卡片，显示：

    - ​**原文**：法条的具体内容。
    - ​**来源**：中国人大网 / CourtListener。
    - ​**可信状态**：✅ Verified on Blockchain (Block #45123)。

  - 点击可跳转到区块链浏览器，查看该法条在 3 年前就被存证且未被修改的记录。

---

## 3. 毕设创新点与学术价值 (Innovation & Value)

### 3.1 结合区块链的 vRAG (Verifiable RAG)

目前的 RAG 技术虽然解决了时效性问题，但无法解决“数据源信任”问题（即 Garbage In, Garbage Out）。本项目提出了一种结合 Merkle Tree 的 RAG 架构，为每一个被检索的 Knowledge Chunk 提供密码学证明。这在法律、医疗等高敏感领域具有极高的推广价值。

### 3.2 法律问答的“零幻觉”范式

通过“封闭域检索”+“链上数据校验”+“严格 Prompt 约束”的三重机制，最大程度地逼近“零幻觉”目标。这不仅仅是一个技术工具，更是对法律 AI 伦理的一种技术实现——​**绝不向用户提供未经核实的法律建议**。
